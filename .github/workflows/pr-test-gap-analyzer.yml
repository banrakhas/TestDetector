name: PR Test Suggestions

on:
  pull_request:
    types: [opened, synchronize]

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  analyze-pr:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Build npm (weather-ui)
        run: |
          cd weather-ui
          npm install
          npm run build

      - name: Build Python (backend)
        run: |
          cd backend
          pip install uv
          uv sync
          # Python build (if needed)
          python -m build || true

      - name: Get PR diff
        run: |
          git fetch origin ${{ github.event.pull_request.base.ref }}
          git diff origin/${{ github.event.pull_request.base.ref }} HEAD > pr_diff.txt || \
          git diff origin/${{ github.event.pull_request.base.ref }}..HEAD > pr_diff.txt

      - name: Get repo tree
        run: |
          git ls-tree -r HEAD --name-only > repo_tree.txt

      - name: Collect test files
        run: |
          find . -type f \( -name "*.spec.ts" -o -name "*.test.ts" -o -name "test_*.py" -o -name "*_test.py" \) > test_files.txt || true

      - name: Read test file contents
        run: |
          if [ -s test_files.txt ]; then
            echo "## Test Files in Repository" > test_details.txt
            echo "" >> test_details.txt
            while IFS= read -r file; do
              echo "### $file" >> test_details.txt
              echo "\`\`\`" >> test_details.txt
              cat "$file" >> test_details.txt
              echo "\`\`\`" >> test_details.txt
              echo "" >> test_details.txt
            done < test_files.txt
          else
            echo "No test files found." > test_details.txt
          fi

      - name: Call LLM API
        id: llm
        env:
          LLM_API_TOKEN: ${{ secrets.LLM_API_TOKEN || '' }}
        run: |
          # Create request payload as a file using jq and reading files directly to avoid long command args
          # (use --rawfile so jq reads file contents instead of passing them via the shell)
          jq -n \
            --rawfile instructions .github/agents/TestGapAnalyzer.md \
            --rawfile pr_diff pr_diff.txt \
            --rawfile repo_tree repo_tree.txt \
            --rawfile test_details test_details.txt \
            '{
              "model": "gpt-oss:120b",
              "messages": [
                {"role": "system", "content": $instructions},
                {"role": "user", "content": ("Code diff:\n" + $pr_diff)},
                {"role": "user", "content": ("Repo tree:\n" + $repo_tree)},
                {"role": "user", "content": ("Existing tests:\n" + $test_details)}
              ]
            }' > llm_request.json

          echo "=== System Instructions (first 1000 chars) ==="
          head -c 1000 .github/agents/TestGapAnalyzer.md || true
          echo ""
          echo ""
          echo "=== Full Request JSON (first 2000 chars) ==="
          head -c 2000 llm_request.json || true
          echo ""
          echo ""
          echo "Request prepared. Calling LLM API..."
          
          # Call LLM API with the request file
          RESPONSE=$(curl -s https://ollama.com/api/chat \
            -H "Authorization: Bearer $LLM_API_TOKEN" \
            -H "Content-Type: application/json" \
            -d @llm_request.json)

          echo "$RESPONSE" > llm_output.json
          # Aggregate streaming or newline-delimited JSON into a single text response.
          # If the API returned one JSON object, extract content; if it returned many JSON objects (stream), join thinking/content fields.
          cat llm_output.json | jq -s -r '
            map(
              if has("choices") then
                (.choices[0].message.content // "")
              elif has("message") then
                ((.message.thinking // "") + (.message.content // ""))
              else
                ""
              end
            ) | join("")
          ' > llm_parsed.txt || true

          echo "=== Parsed LLM Output (first 1000 chars) ==="
          head -c 1000 llm_parsed.txt || true
          echo ""

      - name: Comment on PR
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            let comment = 'Analysis failed or returned empty response';
            try {
              // Prefer the aggregated parsed text if available
              if (fs.existsSync('llm_parsed.txt')) {
                comment = fs.readFileSync('llm_parsed.txt', 'utf8') || comment;
              } else if (fs.existsSync('llm_output.json')) {
                const raw = fs.readFileSync('llm_output.json', 'utf8');
                const parsed = JSON.parse(raw);
                if (parsed.choices && parsed.choices[0] && parsed.choices[0].message) {
                  comment = parsed.choices[0].message.content || comment;
                } else if (parsed.error) {
                  comment = `Error from LLM: ${parsed.error.message || 'Unknown error'}`;
                }
              }
            } catch (e) {
              comment = `Failed to parse LLM output: ${e.message}`;
            }

            // Truncate very long comments to avoid API rejections
            if (comment.length > 64000) {
              comment = comment.slice(0, 64000) + '\n\n[Truncated]';
            }

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Extract Suggested Tests
        id: tests
        run: |
          # Extract test files using the TEST_FILE: format from LLM output
          echo "Extracting test files from LLM output..."
          rm -f tests.txt || true

          # Look for lines matching "TEST_FILE: path/to/test.spec.ts"
          if [ -f llm_parsed.txt ]; then
            grep -E "^TEST_FILE:" llm_parsed.txt | sed 's/^TEST_FILE: *//' > tests.txt || true
          elif [ -f llm_output.json ]; then
            jq -r '.choices[0].message.content // ""' llm_output.json | grep -E "^TEST_FILE:" | sed 's/^TEST_FILE: *//' > tests.txt || true
          else
            echo "No LLM output found to extract tests from." >&2
          fi

          echo "=== Extracted test files ==="
          cat tests.txt || echo "(none found)"
          echo ""

          # Build test run commands
          if [ -s tests.txt ]; then
            echo "found=true" >> $GITHUB_OUTPUT

            # Determine test framework and build appropriate commands
            test_commands=""
            while IFS= read -r test_file; do
              [ -z "$test_file" ] && continue
              if [[ "$test_file" == *.spec.ts ]] || [[ "$test_file" == *.test.ts ]]; then
                # Angular/Jest TypeScript tests
                test_commands+="npm test -- $test_file"$'\n'
              elif [[ "$test_file" == test_*.py ]] || [[ "$test_file" == *_test.py ]]; then
                # Python pytest
                test_commands+="pytest $test_file"$'\n'
              fi
            done < tests.txt

            echo "commands<<EOF" >> $GITHUB_OUTPUT
            echo "$test_commands" >> $GITHUB_OUTPUT
            echo "EOF" >> $GITHUB_OUTPUT
          else
            echo "found=false" >> $GITHUB_OUTPUT
          fi

      - name: Run Suggested Tests
        if: steps.tests.outputs.found == 'true'
        run: |
          echo "Running tests extracted from LLM analysis..."
          cd ${{ github.workspace }}

          # Build a list of include patterns for Angular tests
          ng_includes=""
          pytest_args=""

          while IFS= read -r test_file; do
            [ -z "$test_file" ] && continue

            echo "Queued test: $test_file"

            if [[ "$test_file" == *.spec.ts ]] || [[ "$test_file" == *.test.ts ]]; then
              # Angular/Karma tests - build include patterns
              if [ -z "$ng_includes" ]; then
                ng_includes="--include='$test_file'"
              else
                ng_includes="$ng_includes --include='$test_file'"
              fi
            elif [[ "$test_file" == test_*.py ]] || [[ "$test_file" == *_test.py ]]; then
              # Python pytest - accumulate files
              pytest_args="$pytest_args $test_file"
            fi
          done < tests.txt

          # Run Angular tests if any were queued
          if [ -n "$ng_includes" ]; then
            echo ""
            echo "========================================"
            echo "Running Angular Tests"
            echo "========================================"
            cd weather-ui
            eval "npm test -- $ng_includes -- --watch=false --browsers=ChromeHeadless" || true
            cd ..
          fi

          # Run Python tests if any were queued
          if [ -n "$pytest_args" ]; then
            echo ""
            echo "========================================"
            echo "Running Python Tests"
            echo "========================================"
            cd backend
            pytest $pytest_args || true
            cd ..
          fi

          echo ""
          echo "Test execution completed."